{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h5-yu12sAe76"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class IdentityBlock(nn.Module):\n",
        "    # just add the input as is at the end of forward pass\n",
        "    def __init__(self, input_channels,output_channels,stride=1,downsample=None):\n",
        "        super(IdentityBlock,self).__init__()\n",
        "        padding =1\n",
        "        self.block = torch.nn.Sequential(\n",
        "            nn.Conv2d(input_channels,out_channels=output_channels,kernel_size=3,stride=stride,padding=padding),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=output_channels,out_channels=output_channels,kernel_size=3,stride=1,padding=padding),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "        )\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        residue = x\n",
        "        out = self.block(x)\n",
        "        if self.downsample :\n",
        "            residue = self.downsample(x)\n",
        "        # print(\"out shape :\"+ str(out.shape))\n",
        "        # print(\"residue shape :\"+str(residue.shape))\n",
        "        out += residue\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1,\n",
        "    # padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "    def __init__(self,layers,block,num_of_classes):\n",
        "        super(ResNet,self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv2d(3,self.inplanes,7,2,3),\n",
        "            nn.BatchNorm2d(self.inplanes),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.initial_pool = nn.MaxPool2d(3,2,1)\n",
        "        self.resnet_layer1 = self.layer_with_blocks(block,layers[0],64,stride=1)\n",
        "        self.resnet_layer2 = self.layer_with_blocks(block,layers[1],128,stride=2)\n",
        "        self.resnet_layer3 = self.layer_with_blocks(block,layers[2],256,stride=2)\n",
        "        self.resnet_layer4 = self.layer_with_blocks(block,layers[3],512,stride=2)\n",
        "        self.avg_pool = nn.AvgPool2d(7,stride=1)\n",
        "        self.final = nn.Linear(512,num_of_classes)\n",
        "\n",
        "    def layer_with_blocks(self,block,number_of_blocks,channels,stride=1):\n",
        "        downsample = None\n",
        "        if self.inplanes != channels or  stride != 1:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes,channels,kernel_size=1,stride=stride),\n",
        "                nn.BatchNorm2d(channels)\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes,channels,stride,downsample))\n",
        "        self.inplanes = channels\n",
        "        for i in range(1,number_of_blocks):\n",
        "            layers.append(block(self.inplanes,channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.initial_conv(x)\n",
        "        out = self.initial_pool(out)\n",
        "        out = self.resnet_layer1(out)\n",
        "        # print(\"out.shape after layer 1:\"+str(out.shape))\n",
        "        out = self.resnet_layer2(out)\n",
        "        # print(\"out.shape after layer 2:\"+str(out.shape))\n",
        "        out = self.resnet_layer3(out)\n",
        "        # print(\"out.shape after layer 3:\"+str(out.shape))\n",
        "        out = self.resnet_layer4(out)\n",
        "        # print(\"out.shape after layer 4:\"+str(out.shape))\n",
        "        out = self.avg_pool(out)\n",
        "        # print(\"out.shape avg pool :\"+str(out.shape))\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.final(out)\n",
        "        return out\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "import torchvision\n",
        "# import torch.nn as nn\n",
        "import gc\n",
        "# import resnet\n",
        "\n",
        "# prepare data\n",
        "batch_size = 128\n",
        "num_of_classes = 10\n",
        "\n",
        "# train_dataset = torchvision.datasets.CIFAR10(root=\"./data\",train=True,download=True)\n",
        "# test_dataset = torchvision.datasets.CIFAR10(root=\"./data\",train=False,download=True)\n",
        "transform=torchvision.transforms.Compose([torchvision.transforms.Resize((224,224)),torchvision.transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\",train=True,download=True,transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
        "train_data = iter(train_data_loader)\n",
        "test_data = iter(test_data_loader)\n",
        "# make model\n",
        "model = ResNet([2,2,3,2],IdentityBlock,num_of_classes=num_of_classes)\n",
        "\n",
        "# make loss and optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(),learning_rate,weight_decay=0.001,momentum=0.9)\n",
        "\n",
        "# train loop\n",
        "for epoch in range(epochs):\n",
        "    l = None\n",
        "    for i, (batch,batch_labels) in enumerate(train_data):\n",
        "        predictions = model(batch)\n",
        "        l = loss(predictions,batch_labels)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        del predictions\n",
        "        gc.collect()\n",
        "\n",
        "    # if epoch%10 == 0:\n",
        "        # print loss\n",
        "        print(f'for epoch : {epoch} and iteration:{i} the loss : {l.item()}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (batch,batch_labels) in enumerate(test_data):\n",
        "        predictions = model(batch)\n",
        "        total += batch_labels.shape[0]\n",
        "        _, predicted = torch.max(predictions.data, 1)\n",
        "        total += batch_labels.size(0)\n",
        "        correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "    print(\" accuracy : \"+ str(correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqxTKuUfAk8N",
        "outputId": "d7109ade-457e-4781-d17a-0916ed76e07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "for epoch : 0 and iteration:0 the loss : 2.410749912261963\n",
            "for epoch : 0 and iteration:1 the loss : 2.311783790588379\n",
            "for epoch : 0 and iteration:2 the loss : 2.2927086353302\n",
            "for epoch : 0 and iteration:3 the loss : 2.339174747467041\n",
            "for epoch : 0 and iteration:4 the loss : 2.330965757369995\n",
            "for epoch : 0 and iteration:5 the loss : 2.2805933952331543\n",
            "for epoch : 0 and iteration:6 the loss : 2.3229475021362305\n",
            "for epoch : 0 and iteration:7 the loss : 2.2620816230773926\n",
            "for epoch : 0 and iteration:8 the loss : 2.2387170791625977\n",
            "for epoch : 0 and iteration:9 the loss : 2.1961588859558105\n",
            "for epoch : 0 and iteration:10 the loss : 2.2143776416778564\n",
            "for epoch : 0 and iteration:11 the loss : 2.214686870574951\n",
            "for epoch : 0 and iteration:12 the loss : 2.191342353820801\n",
            "for epoch : 0 and iteration:13 the loss : 2.1476385593414307\n",
            "for epoch : 0 and iteration:14 the loss : 2.20194673538208\n",
            "for epoch : 0 and iteration:15 the loss : 2.160290241241455\n",
            "for epoch : 0 and iteration:16 the loss : 2.1119115352630615\n",
            "for epoch : 0 and iteration:17 the loss : 2.1902592182159424\n",
            "for epoch : 0 and iteration:18 the loss : 2.117849588394165\n",
            "for epoch : 0 and iteration:19 the loss : 2.106100082397461\n",
            "for epoch : 0 and iteration:20 the loss : 2.0747594833374023\n",
            "for epoch : 0 and iteration:21 the loss : 2.0133278369903564\n",
            "for epoch : 0 and iteration:22 the loss : 1.9989831447601318\n",
            "for epoch : 0 and iteration:23 the loss : 2.0011866092681885\n",
            "for epoch : 0 and iteration:24 the loss : 1.9570800065994263\n",
            "for epoch : 0 and iteration:25 the loss : 2.0265469551086426\n",
            "for epoch : 0 and iteration:26 the loss : 2.027808427810669\n",
            "for epoch : 0 and iteration:27 the loss : 2.038078546524048\n",
            "for epoch : 0 and iteration:28 the loss : 1.9166442155838013\n",
            "for epoch : 0 and iteration:29 the loss : 2.073451280593872\n",
            "for epoch : 0 and iteration:30 the loss : 1.8933699131011963\n",
            "for epoch : 0 and iteration:31 the loss : 2.0611062049865723\n",
            "for epoch : 0 and iteration:32 the loss : 1.9796146154403687\n",
            "for epoch : 0 and iteration:33 the loss : 1.9854238033294678\n"
          ]
        }
      ]
    }
  ]
}